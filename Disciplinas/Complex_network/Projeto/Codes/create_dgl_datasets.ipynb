{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0cbf4d-6b63-4155-98ab-1e405068e530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import math\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import urllib.request\n",
    "import pywt\n",
    "import json\n",
    "import scipy\n",
    "import warnings\n",
    "import dgl\n",
    "import torch as th\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.data.utils import save_graphs, load_graphs\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.data import DGLDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from json import JSONEncoder\n",
    "from ts2vg import NaturalVG\n",
    "from scipy.io import loadmat, savemat\n",
    "from scipy import signal\n",
    "from collections import Counter, defaultdict\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8acebf1-b6d8-4bb1-a05e-8c50a862b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the beats\n",
    "with open ('./Datasets/Segmentation_dicts/dict_beats_train.pkl', 'rb') as file_train:\n",
    "    dict_beats_train = pickle.load(file_train)\n",
    "    \n",
    "with open ('./Datasets/Segmentation_dicts/dict_beats_test.pkl', 'rb') as file_test:\n",
    "    dict_beats_test = pickle.load(file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70674fb1-6529-4144-a230-fdf79129932e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of class N: train -> 45844, test -> 44238, total -> 90082 (89.47%)\n",
      "Number of class S: train -> 944, test -> 1837, total -> 2781 (2.76%)\n",
      "Number of class V: train -> 3788, test -> 3220, total -> 7008 (6.96%)\n",
      "Number of class F: train -> 414, test -> 388, total -> 802 (0.80%)\n",
      "Number of class Q: train -> 8, test -> 7, total -> 15 (0.01%)\n",
      "TOTAL OF BEATS: 100688\n"
     ]
    }
   ],
   "source": [
    "#counting the beats in each class\n",
    "sum_beats = len(dict_beats_train['N'])+len(dict_beats_train['S'])+len(dict_beats_train['V'])+len(dict_beats_train['F'])+len(dict_beats_train['Q'])+len(dict_beats_test['N'])+len(dict_beats_test['S'])+len(dict_beats_test['V'])+len(dict_beats_test['F'])+len(dict_beats_test['Q'])\n",
    "\n",
    "a = f\"Number of class N: train -> {len(dict_beats_train['N'])}, test -> {len(dict_beats_test['N'])}, total -> {len(dict_beats_train['N'])+len(dict_beats_test['N'])} ({((len(dict_beats_train['N'])+len(dict_beats_test['N']))/sum_beats)*100:.2f}%)\"\n",
    "b = f\"Number of class S: train -> {len(dict_beats_train['S'])}, test -> {len(dict_beats_test['S'])}, total -> {len(dict_beats_train['S'])+len(dict_beats_test['S'])} ({((len(dict_beats_train['S'])+len(dict_beats_test['S']))/sum_beats)*100:.2f}%)\"\n",
    "c = f\"Number of class V: train -> {len(dict_beats_train['V'])}, test -> {len(dict_beats_test['V'])}, total -> {len(dict_beats_train['V'])+len(dict_beats_test['V'])} ({((len(dict_beats_train['V'])+len(dict_beats_test['V']))/sum_beats)*100:.2f}%)\"\n",
    "d = f\"Number of class F: train -> {len(dict_beats_train['F'])}, test -> {len(dict_beats_test['F'])}, total -> {len(dict_beats_train['F'])+len(dict_beats_test['F'])} ({((len(dict_beats_train['F'])+len(dict_beats_test['F']))/sum_beats)*100:.2f}%)\"\n",
    "e = f\"Number of class Q: train -> {len(dict_beats_train['Q'])}, test -> {len(dict_beats_test['Q'])}, total -> {len(dict_beats_train['Q'])+len(dict_beats_test['Q'])} ({((len(dict_beats_train['Q'])+len(dict_beats_test['Q']))/sum_beats)*100:.2f}%)\"\n",
    "f = f'TOTAL OF BEATS: {sum_beats}'\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1758663-4285-451d-881f-b4581fae2b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering the majoritary classes\n",
    "keys =['N','S','V']\n",
    "dict_train = dict(zip(keys, [dict_beats_train[k] for k in keys]))\n",
    "dict_test = dict(zip(keys, [dict_beats_test[k] for k in keys]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3cfc49a-d75f-49b0-9bdb-05dd274bfeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_N_beats_train = random.sample(dict_train['N'], 3000)\n",
    "select_N_beats_test = random.sample(dict_test['N'], 3000)\n",
    "dict_train['N'] = select_N_beats_train\n",
    "dict_test['N'] = select_N_beats_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b5f7e7-cf8d-4cea-9698-01afae4227eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of class N: train -> 3000, test -> 3000, total -> 6000 (38.00%)\n",
      "Number of class S: train -> 944, test -> 1837, total -> 2781 (17.61%)\n",
      "Number of class V: train -> 3788, test -> 3220, total -> 7008 (44.39%)\n",
      "\n",
      "\n",
      "TOTAL OF BEATS:    train -> 7732, test -> 8057,total -> 15789\n"
     ]
    }
   ],
   "source": [
    "#counting the beats in each class after the reduction class N\n",
    "sum_beats = len(dict_train['N'])+len(dict_train['S'])+len(dict_train['V'])+len(dict_test['N'])+len(dict_test['S'])+len(dict_test['V'])\n",
    "\n",
    "a = f\"Number of class N: train -> {len(dict_train['N'])}, test -> {len(dict_test['N'])}, total -> {len(dict_train['N'])+len(dict_test['N'])} ({((len(dict_train['N'])+len(dict_test['N']))/sum_beats)*100:.2f}%)\"\n",
    "b = f\"Number of class S: train -> {len(dict_train['S'])}, test -> {len(dict_test['S'])}, total -> {len(dict_train['S'])+len(dict_test['S'])} ({((len(dict_train['S'])+len(dict_test['S']))/sum_beats)*100:.2f}%)\"\n",
    "c = f\"Number of class V: train -> {len(dict_train['V'])}, test -> {len(dict_test['V'])}, total -> {len(dict_train['V'])+len(dict_test['V'])} ({((len(dict_train['V'])+len(dict_test['V']))/sum_beats)*100:.2f}%)\"\n",
    "d = f\"TOTAL OF BEATS:    train -> {len(dict_train['N'])+len(dict_train['S'])+len(dict_train['V'])}, test -> {len(dict_test['N'])+len(dict_test['S'])+len(dict_test['V'])},\\\n",
    "total -> {len(dict_train['N'])+len(dict_train['S'])+len(dict_train['V'])+len(dict_test['N'])+len(dict_test['S'])+len(dict_test['V'])}\"\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print('\\n')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7c7e417-e455-462c-8614-76a2e5941897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the beats in a graph using visibility graph and convert to a dgl graph format\n",
    "\n",
    "def convert_beats_in_graphs(dict_train, dict_test):\n",
    "    \n",
    "    #auxiliar variables to training beats\n",
    "    train_edges={}\n",
    "    train_properties={}\n",
    "    train_graph_id=[]\n",
    "    train_graph_src=[]\n",
    "    train_graph_dst=[]\n",
    "    train_graph_nodes=[]\n",
    "    train_graph_label=[]\n",
    "\n",
    "    #auxiliar variables to test beats\n",
    "    test_edges={}\n",
    "    test_properties={}\n",
    "    test_graphs={}\n",
    "    test_graph_id=[]\n",
    "    test_graph_src=[]\n",
    "    test_graph_dst=[]\n",
    "    test_graph_nodes=[]\n",
    "    test_graph_label=[]\n",
    "\n",
    "    #encoding classes\n",
    "    #classes=[0,1,2]\n",
    "    classes =['N','S','V']\n",
    "    train_id = 0\n",
    "    test_id = 0\n",
    "\n",
    "\n",
    "    #-----------------------------TRAINING DATASET---------------------------------------------------\n",
    "    #iterate in dict of beats in training dataset\n",
    "    for classes_, beats in dict_train.items(): \n",
    "        #iterate of all beats\n",
    "        for beat in beats: \n",
    "            #getting the graph label  \n",
    "            label = classes.index(classes_)    \n",
    "            #converting the beat in a graph using visibility graph\n",
    "            g = NaturalVG(directed=None).build(beat) \n",
    "            #converting the graph in a igraph graph format\n",
    "            igg = g.as_igraph() \n",
    "\n",
    "            # source nodes from each edge \n",
    "            source_nodes_ids = [i[0] for i in ig.Graph.get_edgelist(igg)] \n",
    "            #destination nodes from each edge \n",
    "            destination_nodes_ids = [i[1] for i in ig.Graph.get_edgelist(igg)]\n",
    "            #number of nodes\n",
    "            num_nodes=igg.vcount()   \n",
    "\n",
    "            #saving information\n",
    "            train_graph_id.extend([train_id]*len(ig.Graph.get_edgelist(igg)))\n",
    "            train_graph_src.extend(source_nodes_ids)\n",
    "            train_graph_dst.extend(destination_nodes_ids)\n",
    "            train_graph_nodes.extend([num_nodes]*len(ig.Graph.get_edgelist(igg)))\n",
    "            train_graph_label.extend([label]*len(ig.Graph.get_edgelist(igg)))\n",
    "            \n",
    "            train_id += 1\n",
    "            \n",
    "    #saving the graph informations\n",
    "    train_edges.update({'graph_id': train_graph_id,\n",
    "                        'src': train_graph_src,\n",
    "                        'dst': train_graph_dst})\n",
    "    \n",
    "    train_properties.update({'graph_id': train_graph_id,\n",
    "                             'label': train_graph_label,\n",
    "                             'num_nodes': train_graph_nodes})\n",
    "    \n",
    "    #creating a dataframe and saving in file.csv\n",
    "    df_train_edges = pd.DataFrame(train_edges)\n",
    "    df_train_edges.to_csv('./Datasets/Dgl_beats_graphs/df_train_edges.csv', index=False)\n",
    "    df_train_properties = pd.DataFrame(train_properties)\n",
    "    df_train_properties.drop_duplicates(inplace=True)\n",
    "    df_train_properties.to_csv('./Datasets/Dgl_beats_graphs/df_train_properties.csv', index=False)\n",
    " \n",
    "    #-----------------------------TEST DATASET---------------------------------------------------\n",
    "    \n",
    "    #iterate in dict of beats in test dataset\n",
    "    for classes_, beats in dict_test.items(): \n",
    "        #iterate of all beats\n",
    "        for beat in beats: \n",
    "            #getting the graph label  \n",
    "            label = classes.index(classes_)    \n",
    "            #converting the beat in a graph using visibility graph\n",
    "            g = NaturalVG(directed=None).build(beat) \n",
    "            #converting the graph in a igraph graph format\n",
    "            igg = g.as_igraph() \n",
    "\n",
    "            # source nodes from each edge \n",
    "            source_nodes_ids = [i[0] for i in ig.Graph.get_edgelist(igg)] \n",
    "            #destination nodes from each edge \n",
    "            destination_nodes_ids = [i[1] for i in ig.Graph.get_edgelist(igg)]\n",
    "            #number of nodes\n",
    "            num_nodes=igg.vcount()   \n",
    "\n",
    "            #saving information\n",
    "            test_graph_id.extend([test_id]*len(ig.Graph.get_edgelist(igg)))\n",
    "            test_graph_src.extend(source_nodes_ids)\n",
    "            test_graph_dst.extend(destination_nodes_ids)\n",
    "            test_graph_nodes.extend([num_nodes]*len(ig.Graph.get_edgelist(igg)))\n",
    "            test_graph_label.extend([label]*len(ig.Graph.get_edgelist(igg)))\n",
    "            \n",
    "            test_id += 1\n",
    "            \n",
    "    #saving the graph informations\n",
    "    test_edges.update({'graph_id': test_graph_id,\n",
    "                        'src': test_graph_src,\n",
    "                        'dst': test_graph_dst})\n",
    "    \n",
    "    test_properties.update({'graph_id': test_graph_id,\n",
    "                             'label': test_graph_label,\n",
    "                             'num_nodes': test_graph_nodes})\n",
    "    \n",
    "    #creating a dataframe and saving in file.csv\n",
    "    df_test_edges = pd.DataFrame(test_edges)\n",
    "    df_test_edges.to_csv('./Datasets/Dgl_beats_graphs/df_test_edges.csv', index=False)\n",
    "    df_test_properties = pd.DataFrame(test_properties)\n",
    "    df_test_properties.drop_duplicates(inplace=True)\n",
    "    df_test_properties.to_csv('./Datasets/Dgl_beats_graphs/df_test_properties.csv', index=False)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "380d03ba-5d4a-47b5-9cda-63f6b82e5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the beats\n",
    "convert_beats_in_graphs(dict_train, dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca1d72b0-ac7c-4e40-80ce-84cf0901cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the files\n",
    "edges_train = pd.read_csv('./Datasets/Dgl_beats_graphs/df_train_edges.csv')\n",
    "properties_train = pd.read_csv('./Datasets/Dgl_beats_graphs/df_train_properties.csv')\n",
    "\n",
    "edges_test = pd.read_csv('./Datasets/Dgl_beats_graphs/df_test_edges.csv')\n",
    "properties_test = pd.read_csv('./Datasets/Dgl_beats_graphs/df_test_properties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23adee1d-91a7-4523-bdfa-6ec95e54041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataset_train(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='synthetic')\n",
    "\n",
    "    def process(self):\n",
    "        edges = pd.read_csv('./Datasets/Dgl_beats_graphs/df_train_edges.csv')\n",
    "        properties = pd.read_csv('./Datasets/Dgl_beats_graphs/df_train_properties.csv')\n",
    "        self.graphs = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Create a graph for each graph ID from the edges table.\n",
    "        # First process the properties table into two dictionaries with graph IDs as keys.\n",
    "        # The label and number of nodes are values.\n",
    "        label_dict = {}\n",
    "        num_nodes_dict = {}\n",
    "        for _, row in properties.iterrows():\n",
    "            label_dict[row['graph_id']] = row['label']\n",
    "            num_nodes_dict[row['graph_id']] = row['num_nodes']\n",
    "\n",
    "        # For the edges, first group the table by graph IDs.\n",
    "        edges_group = edges.groupby('graph_id')\n",
    "\n",
    "        # For each graph ID...\n",
    "        for graph_id in edges_group.groups:\n",
    "            # Find the edges as well as the number of nodes and its label.\n",
    "            edges_of_id = edges_group.get_group(graph_id)\n",
    "            src = edges_of_id['src'].to_numpy()\n",
    "            dst = edges_of_id['dst'].to_numpy()\n",
    "            num_nodes = num_nodes_dict[graph_id]\n",
    "            label = label_dict[graph_id]\n",
    "\n",
    "            # Create a graph and add it to the list of graphs and labels.\n",
    "            g = dgl.graph((src, dst), num_nodes=num_nodes)\n",
    "            self.graphs.append(g)\n",
    "            self.labels.append(label)\n",
    "\n",
    "        # Convert the label list to tensor for saving.\n",
    "        self.labels = th.LongTensor(self.labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "527747f6-9a7a-4c3a-8975-410ad552510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataset_test(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='synthetic')\n",
    "\n",
    "    def process(self):\n",
    "        edges = pd.read_csv('./Datasets/Dgl_beats_graphs/df_test_edges.csv')\n",
    "        properties = pd.read_csv('./Datasets/Dgl_beats_graphs/df_test_properties.csv')\n",
    "        self.graphs = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Create a graph for each graph ID from the edges table.\n",
    "        # First process the properties table into two dictionaries with graph IDs as keys.\n",
    "        # The label and number of nodes are values.\n",
    "        label_dict = {}\n",
    "        num_nodes_dict = {}\n",
    "        for _, row in properties.iterrows():\n",
    "            label_dict[row['graph_id']] = row['label']\n",
    "            num_nodes_dict[row['graph_id']] = row['num_nodes']\n",
    "\n",
    "        # For the edges, first group the table by graph IDs.\n",
    "        edges_group = edges.groupby('graph_id')\n",
    "\n",
    "        # For each graph ID...\n",
    "        for graph_id in edges_group.groups:\n",
    "            # Find the edges as well as the number of nodes and its label.\n",
    "            edges_of_id = edges_group.get_group(graph_id)\n",
    "            src = edges_of_id['src'].to_numpy()\n",
    "            dst = edges_of_id['dst'].to_numpy()\n",
    "            num_nodes = num_nodes_dict[graph_id]\n",
    "            label = label_dict[graph_id]\n",
    "\n",
    "            # Create a graph and add it to the list of graphs and labels.\n",
    "            g = dgl.graph((src, dst), num_nodes=num_nodes)\n",
    "            self.graphs.append(g)\n",
    "            self.labels.append(label)\n",
    "\n",
    "        # Convert the label list to tensor for saving.\n",
    "        self.labels = th.LongTensor(self.labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1567ae92-6de3-4099-bef6-205d41127e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = SyntheticDataset_train()\n",
    "dataset_test = SyntheticDataset_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
